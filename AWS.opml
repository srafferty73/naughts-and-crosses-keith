<?xml version="1.0" encoding="UTF-8"?>
<opml version="1.0">
    <head>
        <title>AWS</title>
    </head>
    <body>
        <outline text="AWS">
            <outline text="Chapter 1 Introduction">
                <outline text="Virtualisation ">
                    <outline text="Flexible"></outline>
                    <outline text="Fast to provision"></outline>
                    <outline text="Only use as much
as you need"></outline>
                </outline>
                <outline text="Cloud Computing
Architecture">
                    <outline text="On-demand &amp; Self-service"></outline>
                    <outline text="Cost efficient" _note="Billed only for what you consume. Often cheaper than trad services  Moving away from CAPEX and moving toward OPEX.  No large initial spend on hardware, premises etc.  If new advances in hardware become available, you can adjust within AWS quickly rather than having to spend money to buy new equipment."></outline>
                    <outline text="Scalability " _note="Can automatically meet unexpected increases in demand.  In essence, elasticity is the broader concept, and autoscaling is a tool to achieve it."></outline>
                    <outline text="Elasticity" _note="Can respond to increase &amp; decrease as required.  Can ramp up when demand requires it and down when demand is reduced.  This is a great way to help save costs."></outline>
                </outline>
                <outline text="AWS Platform
Architecture">
                    <outline text="Regions" _note="An AWS region is a separate geographic area where AWS has one or more data centers. These regions are strategically placed around the globe to cover every area on Earth.    Mostly nongovernmental Some governmental Couple of Chinese ones">
                        <outline text="Availability Zones" _note="Physical AWS datacenter exposed within your AWS account.    Usually a minimum of 3 per Region but can be up to around 6."></outline>
                        <outline text="VPC" _note="Virtual Private Cloud  A VPC is effectively a network address space within which you can create network subnets and associate them with Availability Zones.  When configured properly, this architecture can provide effective resource isolation and durable replication."></outline>
                    </outline>
                </outline>
                <outline text="AWS Reliability &amp;
Compliance">
                    <outline text="AWS Shared
Responsibility
Model" _note="The customer is responsible for   What's IN the Cloud Customer Data User Applications, Access Management Operating System, Network and Access Configuration  Data Encryption    AWS is responsible for   The Cloud itself Hardware and Network Maintenance  AWS Global Infrastructure  Managed Services">
                        <outline text="The AWS SLA" _note="The exact percentage of the guarantee will differ according to service.  EC2 - 99.99% uptime (basically, all but 4 mins per month)  It is not IF things will fail but WHEN.  Build applications to be geographically dispersed and fault-tolerant so that when things do break, your users will barely notice."></outline>
                    </outline>
                    <outline text="Working with AWS">
                        <outline text="AWS Organisations" _note="Share resources through a unified AWS Single Sign-on configuration that applies global permissions to all your accounts.  Apply IAM rules globally through service control policies (SCPs)  Create and manage accounts - along with account users and groups - programmatically.  Audit, monitor, and secure all your environments for compliance and functional purposes.  A single account's CloudTrail service can be configured to watch events from your entire organisation."></outline>
                        <outline text="AWS Control Tower" _note="Provides 'landing zones' generated by Control Tower.  Landing zones streamline the onboarding of new accounts automatically applying your organisation's governance policies and incorporating then into your cloud infrastructure."></outline>
                        <outline text="AWS Service Catalog" _note="Customised bundles of resources through a CloudFormation template that points to just the tools you want for a particular team when setting up."></outline>
                        <outline text="AWS Licence Manager" _note="Helps you manage your software licences.  Ensures no violations, track usage, monitor compliance and enforcing rules.  On-prem and cloud-based  Can be used without incurring additional costs."></outline>
                        <outline text="AWS Artifact" _note="Digital repository that allows customers to download compliance-related information about their AWS accounts and services."></outline>
                        <outline text="AWS CLI" _note="Command Line Interface.  Alternative to using the AWS Dashboard GUI.  For certain tasks (repetitive or technical), the CLI is a preferable tool to use.   Scripts can be used to run automated steps etc.  Each command in the CLI is usually started by the letters 'was', e.g.   aws s3 ls  aws s3 mb &lt;bucketname&gt; aws s3 cp /path/to/file.txt s3://bucketname"></outline>
                        <outline text="AWS SDKs" _note="Software Development Kit tools available for a number of common programming languages."></outline>
                        <outline text="Technical Support &amp;
Online Resources" _note="Basic plan Free with every account Access to CS   Other plans are more extensive and expensive  and include:  Developer Business Enterprise On-Ramp Enterprise  Full details here https://aws.amazon.com/premiumsupport/plans/"></outline>
                    </outline>
                </outline>
                <outline text="Migrating Existing
Resources to AWS">
                    <outline text="AWS Migration Hub" _note="Service that helps organisations track their progress as they migrate their workloads to the AWS cloud.  Has a dashboard that provides a central place to view information re your existing inventory and the status of your migration projects."></outline>
                    <outline text="AWS Application
Migration Service" _note="Automates the testing and transfer of AWS-bound migrations of your non-cloud application servers.  You would install the AWS Replication Agent on each of the servers you want migrated.  In an ideal case, the entire lift and shift process can be virtually hands-free."></outline>
                    <outline text="AWS Database
Migration Service" _note="Same basic goal as Application Migration Service but for databases.  No agent installation required.  Many choices available.  Homogenous migration (e.g. Like-to-Like)  Or you can convert a relational database to a data lake that lives in Amazon S3 Or move an Oracle database to Amazon's own Aurora."></outline>
                    <outline text="AWS Application
Discovery Service" _note="Helps you plan application migration projects by identifying which applications are running in your on-prem datacenter, how they are interconnected and how they use your resources.  It then creates a configuration model of your applications and their dependencies."></outline>
                </outline>
            </outline>
            <outline text="Chapter 2
Compute
Services">
                <outline text="Amazon Elastic Compute Cloud (EC2)" _note="Virtualised and abstracted subset of a physical server.
Behaves just like the real thing.">
                    <outline text="EC2 Amazon
Machine Images
(AMI)" _note="An AMI is a template document that contains information telling EC2 what OS and application software to include on the root data volume of the instance it's about to launch.">
                        <outline text="Amazon Quick Stars AMIs" _note="AMIs that are popular choices and that include various releases of Linux or Windows Server OS or macOS.

These AMIs are up-to-date and officially supported."></outline>
                        <outline text="AWS Marketplace AMIs" _note="AMIs from the AWS Marketplace are official, production-ready images provided and supported by industry vendors like Splunk and TrendMicro."></outline>
                        <outline text="Community AMIs" _note="More than 500 images are available ass community AMIs.  Many of these images are AMIs created and maintained by independent vendors and are usually built to meet a specific need.

Good catalogue to search if you're planning an application built on a custom combination of software resources."></outline>
                        <outline text="Private AMIs" _note="You can also store images created from your own instance deployments as private AMIs.

Having a reliable, tested, and patched instance image as an AMI makes incorporating autoscaling easy.

You can also share images as AMIs or import VMs from your local infrastructure (by way of AWS S3) using the AWS VM Import/Export tool."></outline>
                    </outline>
                    <outline text="BILLING" _note="Beside the normal charges for running an EC2 instance, your AWS account might also be billed hourly amounts or licence fees for the use of the AMI software itself.

Although vendors make every effort to clearly display the charges for their AMIs, it's YOUR responsibility to accept and honour those charges."></outline>
                    <outline text="Instance Types">
                        <outline text="General purpose" _note="Aim to provide a balance of compute, memory and network resources.

T2 types are 'burstable', which means you can accumulate CPU credits when your instance is under-utilised that can be applied during high-demand periods in the form of higher CPU performance."></outline>
                        <outline text="Compute optimised" _note="For more demanding web servers and high-end machine learning workloads."></outline>
                        <outline text="Memory optimised" _note="These work well for intensive database, data analysis, and caching operations.  They tend to emphasise higher memory bandwidth and superior networking speeds."></outline>
                        <outline text="Accelerated computing" _note="Higher performing general-purpose graphics processing unit performance.

Recommended for demanding workloads such as high-performance computing (HPC) and high-end financial, engineering, artificial intelligence workloads, and medical research."></outline>
                        <outline text="Storage optimised" _note="Can deliver fast read/writes and come with low-latency access to ENS instance storage volumes.

These instances work well with distributed filesystems and heavyweight data processing applications."></outline>
                    </outline>
                    <outline text="AWS Regions" _note="You'll generally want to launch an EC2 instance in the region that's physically closest to the majority of your customers 

or, 

if you're working with data that's subject to legal restrictions (like data sovereignty requirements), within a jurisdiction that meets your compliance needs.">
                        <outline text="A particular AMI will be available in
only a SINGLE REGION."></outline>
                        <outline text="Costs and functionality of
services/features might vary between
regions"></outline>
                    </outline>
                    <outline text="Virtual Private
Clouds (VPCs)">
                        <outline text="Easy to isolate the instances in
one VPC from whatever else
you have running"></outline>
                        <outline text="Adding a simple VPC won't
cost you anything"></outline>
                    </outline>
                    <outline text="Tenancy">
                        <outline text="Shared tenancy" _note="Your instance will run as a virtual machine on a physical server that's concurrently hosting OTHER instances."></outline>
                        <outline text="Dedicated Instance/Host" _note="Your instance won't be sharing the server with resources owned by a different customer account.

Further, you can choose a Dedicated Host - which means that not only will your instance not be sharing, but with Dedicated Host the physical server is basically yours. It does not change, it's always the same physical machine for as long as you are paying."></outline>
                    </outline>
                    <outline text="Configuring
Instance
Behaviour">
                        <outline text="Via configuration
Bootstrapping or Script
files etc"></outline>
                    </outline>
                    <outline text="Placement Groups (requesting separation of instances)" _note="By default, AWS will attempt to spread your instances across their infrastructure to create a profile that will be optimal for most use cases.">
                        <outline text="Cluster" _note="Launch each associated instance into a single availability zone within close physical proximity to each other.

This provides low-latency network interconnectivity and can be useful for HPC applications for instance."></outline>
                        <outline text="Spread" _note="Separate instances physically across distinct hardware racks and even availability zones to reduce the risk of failure-related data or service loss.

Valuable when running hosts that can't tolerate multiple concurrent failures."></outline>
                        <outline text="Partition" _note="Let you associate some instances with each other, placing them in a single 'partition'.

But the instances within that single partition can be kept physically separated from instances within other partitions.

Differs from Spread where no two instances will ever share physical hardware."></outline>
                    </outline>
                    <outline text="Instance Pricing">
                        <outline text="On-demand model" _note="Always-on deployments
Expected to run &lt; 12 months
Normally pay for each hour your instance is running.

Most flexible way to consume EC2
You're able to closely control how much you pay by stopping/starting your instance according to your need.

But, per hour, it's the most expensive."></outline>
                        <outline text="Reserved instance" _note="Term commitment of between 1-3 years.

Keep the lights burning 24/7 for more than a year.

You can either 

1. pay up front for the entire term
OR 
(for incrementally higher rates), 
either 
2. partially up front and the rest in monthly charges 
OR
3. Entirely through monthly charges"></outline>
                        <outline text="Spot market" _note="For workloads that can withstand unexpected disruption.

You enter a max dollar-value bid for an instance type running in a particular region.

Next time an instance in that region becomes available at a per-hour rate =&lt; your bid, it'll be launched using the AMI and launch template you specified.

Once up, it will keep running either

1. Until you stop it (e.g. your workload completes)
2. The instance's per-hour rate rises above your max bid."></outline>
                    </outline>
                    <outline text="Instance Life Cycle">
                        <outline text="Terminating" _note="Causes the instance to shut down and have its resources reallocated to the general AWS pool.

In most cases, this will DESTROY all data kept on the primary storage (but not Elastic Block Store - EBS)."></outline>
                        <outline text="Stopping and restarting" _note="Data is not lost with this solution.

Use if your instance won't be needed for some time but you don't want to terminate it.">
                            <outline text="IP Address handling" _note="If using a non persistent public IP address, it will most likely be assigned a different address when it's restarted.

If y ou need a predictable IP address that can survive restarts, allocate an ELASTIC IP address and associate it with your instance."></outline>
                        </outline>
                    </outline>
                    <outline text="Resource Tags" _note="Can be used to label everything you'll ever touch across your AWS account - not just EC2.

Tags have a 
key 
and (optionally)
an associated value

Example
The key 
production-server 
could be assigned to each element of a prod deploy.

Server instances could, in addition, have a value of 
server1
server2 
etc

So,
production-server: server1
production-server: server2


A related security group could have the same 
production-server
key but
security-group1
For it's value

So,
production-server: security-group1"></outline>
                    <outline text="Service Limits" _note="By default, each AWS account has limits to the number of instances of a particular service you're able to launch.

Sometimes for a region.
Sometimes global.

e.g.
Allowed only 5 VPCs per region
And 5000 SSH key pairs across your account.

You can ask AWS to raise the ceiling for a particular service."></outline>
                </outline>
                <outline text="EC2 Storage Volumes" _note="Generally, presented exactly as though they were normal physical drives.">
                    <outline text="Elastic Block
Store (EBS) Volumes" _note="Attach as many as you like 

One volume can be attached to no more than a single instance at a time.

AWS SLA Guarantee in place for reliability of data - no worry about failure.

The type of EBS volume you choose will have an impact on both performance and cost.

Can use AWS Data Lifecycle Manager can be configured to automate the creation, retention and deletion of your EBS-based snapshots and AMIs.">
                        <outline text="EBS-Provisioned
IOPS SSD" _note="If your applications will require intense rates of I/O operations.

3 flavours

io1
io2
io2 Block Express"></outline>
                        <outline text="EBS
General-Purpose
SSD" _note="For most regular server workloads that, ideally, deliver low-latency performance, these will work well."></outline>
                        <outline text="HDD Volumes" _note="For large data stores where quick access isn't important.

Cost savings"></outline>
                        <outline text="EBS Volume Features" _note="Can be copied by creating a snapshot.

Existing snapshots can be used to generate other volumes that can be shared and/or attached to other instance or converted to images from which AMIs can be made.

Can be encrypted both at rest and in transit

Encryption Keys can either be 
Managed by EBS
Or
You provide them via AWS Key Management Service (KMS)"></outline>
                    </outline>
                    <outline text="Instance Store Volumes (ephemeral)" _note="Unlike EBS Volumes, these are ephemeral.

When the instances they are attached to are shut down, their data is permanently lost.

Are SSDs physically attached to the server hosting your instance
Are connected via a fast Non-Volatile Memory Express (NVMe) interface.

Their use is included in the price of the instance itself.

They work especially well for deployment models where instances are launched to fill short-term roles, import data from external sources and are disposable."></outline>
                </outline>
                <outline text="Accessing Your
EC2 Instance" _note="The three IP address ranges used by private networks:

From  To
10.0.0.0  10.255.255.255
172.16.0.0 172.31.255.255
192.168.0.0 192.168.255.255



You'll only be able to connect to your instance from within its subnet

The instance will have no direct connection to the internet.

You can create one or more virtual elastic network interfaces (ENIs) which must be already connected to an existing subnet/security group.

A public IP address can be assigned, however the default public IP address is ephemeral.

You can allocate a permanent elastic IP for long-term deployments. As long as its attached to a running instance, there's no charge for elastic IPs."></outline>
                <outline text="Securing Your
EC2 Instance">
                    <outline text="Security Groups" _note="Plays the role of a firewall.

By default, will

DENY all incoming traffic.
ALLOWING all outgoing traffic.

You define group behaviour by setting policy rules that will either BLOCK or ALLOW specified traffic types.

Traffic is assessed by examining its source and destination, the targeted network port and its protocol.

They control traffic at the INSTANCE level.  An alternative would be an Network Access Control List (NACL) that are associated with entire subnets."></outline>
                    <outline text="Identity and Access
Management (IAM)" _note="You define an IAM role by giving it permissions to perform actions on specified services or resources within your AWS account.

These IAM roles can then be assigned to users or resources and they would gain access to whichever resources  were included in the role polices.

You can even assign an IAM role to an EC2 instance.  This would enable processes running within it to access the external tools."></outline>
                    <outline text="Network Address
Translation (NAT)" _note="If, for example, an instance needs internet access to receive security patches and software updates.

Allows an EC2 instance access TO the internet without allowing access FROM the internet.

Can be done either via a
NAT instance 
or a
NAT gateway."></outline>
                    <outline text="Key Pairs" _note="Remote login sessions on your running instances should never be initiated over unencrypted plain-text connections.

Save the public key to your EC2 server
Save the private key to your local machine."></outline>
                </outline>
                <outline text="EC2 Auto Scaling" _note="Works by provisioning and starting on your behalf a number of EC2 instances.

It can

Dynamically add more instances to keep up with increased demand.

When an instance fails or gets terminated, it will automatically replace it.


It uses either a 
Launch configuration
or a 
Launch template
to automatically configure the instances that it launches.

Both do the same thing.
The former is the older of the two.">
                    <outline text="Launch Configurations" _note="A named document that contains the same information you'd provide when manually provisioning an instance.

Used only with EC2 Auto Scaling

Once created, you can't modify it.  You'd instead have to create an entirely new configuration."></outline>
                    <outline text="Launch Templates" _note="Similar to Launch Configurations.

However, they are more versatile.
In addition to being used on EC2 Auto Scaling, they can be used for spinning up one-off EC2 instances or even creating a spot fleet.

They are versioned - so you can change them after creation.

Any change means creating a new version.  AWS keeps all versions as needed."></outline>
                    <outline text="Auto Scaling Groups" _note="A group of EC2 instances that Auto Scaling manages

Firstly, choose either a 
Launch Configuration
or a 
Launch Template">
                        <outline text="Specifying a
Load Balancer" _note="Just plug in the name of the load balancer when creating the Auto Scaling group."></outline>
                        <outline text="Health Checks Against
Application Instances" _note="Auto Scaling will strive to maintain the minimum number of instances, or the desired number if you've specified it.

If an instance becomes unhealthy, Auto Scaling will terminate and replace it."></outline>
                        <outline text="Configuring
Scaling Policies" _note="How many running instances you want it to provision and maintain using the configuration or template you created.

You must specify the minimum and maximum size of the Auto Scaling group.

Min - will never go below.  If set to 0, will terminate all running instances in the group.

Max - will never exceed this amount (eg. For budget reasons etc).

You may optionally set the desired number of instances you want Auto Scaling to provision and maintain.

Desired - if not specified, will use Min instead.  Both Min and Max are hard limits, whilst Desired is a dynamic preference that Auto Scaling will aim for wherever possible."></outline>
                        <outline text="Auto Scaling Options">
                            <outline text="Manual Scaling" _note="Whenever you change the desired capacity, Auto Scaling will terminate or add instances to arrive at your selection.

Think of desired capacity as a thermostat."></outline>
                            <outline text="Dynamic Scaling Policies" _note="Automatically provision more instances before they hit the point of running out of instance resources.

Auto Scaling generates the following aggregate metrics for all instances within the group:

Average CPU utilisation 
Average request count per target
Average network bytes in
Average network bytes out

You can also use CloudWatch logs to determine how long it normally takes to complete a process and spin up new instances if it takes longer.">
                                <outline text="Simple Scaling Policies" _note="Whenever the metric rises above a set threshold Auto Scaling simply increases the desired capacity.

How much depends on which of the following adjustment types you choose:

ChangeInCapacity 
You could have a desired capacity of 4 and increase by 2 when load increases.

ExactCapacity
Sets the capacity to a specific value regardless of current value (e.g. desired is 4, change to 6)

PercentChangeInCapacity
Increase the capacity by a percentage of the current amount (e.g. desired is 4, change set to 50% - therefore will be bumped to 6)."></outline>
                                <outline text="Step Scaling Policies" _note="This allows you to add instances based on how much the aggregate metric exceeds the threshold.

Example
When average CPU utilisation hits 50%, add 2 more instances.
When average CPU utilisation hits 60%, add 4 more instances.


Firstly, set a CloudWatch Alarm to monitor

Then specify at least one step adjustment - which must consist of the following:

A lower bound
An upper bound
The adjustment type
The amount by which to increase the desired capacity.


You can optionally specify a warm-up time, which is how long Auto Scaling will wait until considering the metrics of newly added instances.  

Default warm-up time is 300 seconds.

There are no cool-down periods"></outline>
                                <outline text="Target Tracking Policies" _note="Select a metric and target value and Auto Scaling will create a Cloutwatch Alarm and a scaling policy to adjust the number of instances to keep the metric near that target."></outline>
                                <outline text="Scheduled Actions" _note="For a predictable load pattern and you want to adjust your capacity proactively.

You must specify
A minimum, maximum or desired capacity value.
A start date and time

You may optionally set the policy to recur at regular intervals 

You can set an end time, after which the scheduled policy gets deleted."></outline>
                            </outline>
                        </outline>
                    </outline>
                </outline>
                <outline text="AWS Systems Manager">
                    <outline text="Actions" _note="Let you automatically or manually perform actions against your AWS resources, either individually or in bulk.

These actions must be defined in documents, which are divided into three types">
                        <outline text="Automation" _note="Enables you to perform actions against your AWS resources in bulk.

Provides granular control over how it carries out its individual actions.

Can perform all automation tasks in one fell swoop.

OR 

Can perform one step at a time, enabling you to control precisely what happens and when.

Rate Control
you can specify as a number/percentage how many resources to target at once."></outline>
                        <outline text="Run Command" _note="These let you execute tasks on your managed instances that would otherwise require logging in or using a third-party tool to execute a custom script.

Accomplished via an agent installed on your EC2 and on-prem managed instances.

It is installed by default.

It doesn't have any permissions by default - an instance profile role must firstly be applied.

You can target instances by tag 
OR
You can select them individually 

As with automation, you may use rate limiting to control how many instances you target at once."></outline>
                        <outline text="Session Manager" _note="Lets you achieve interactive Bash and PowerShell access to Linux and Windows Instances

You don't have to worry about opening inbound ports on a security group or network ACL
Or even having your instances in a public subnet.

Requires you install the Session Manager plug-in on your local machine

You can open a session using either the web console or AWS CLI

Secured connection via TLS 1.2

Can keep a log of all logins via CloudTrail
Can store a record of commands run within a session in an S3 bucket."></outline>
                        <outline text="Patch Manager" _note="Helps you automate the patching of your Linux and Windows instances.

Works on a wide range of OS

You can 
individually choose instances to patch
patch according to tags OR
create a patch group

A patch group is a collection of instances with the tag key Patch Group.
The tag key is case-sensitive.

Uses patch baselines to define which available patches to install, as well as whether the patches will be installed automatically or require approval.

Patch baselines are approved automatically within 7 days - called auto-approval delay.

Custom baselines can be created also."></outline>
                        <outline text="State Manager" _note="A configuration management tool that ensures your instances have the software you want them to have and are configured in the way you define.

Can automatically run command and policy documents against your instances, either one time only or on a schedule.

To use, you must create an association that defines

- the command document to run
- any parameters you want to pass to it
- the target instances
- the schedule"></outline>
                    </outline>
                    <outline text="Insights" _note="These aggregate health compliance and operational details about your AWS resources into a single area of AWS Systems Manager.

AWS resource groups - collections of resources in an AWS region.
Defined by one or more tag keys and (optionally) tag values.">
                        <outline text="Built-In Insights" _note="Monitoring view that Systems Manager makes available to you by default.">
                            <outline text="AWS Config Compliance" _note="Total number of resources in a resource group that are compliant or non-compliant with AWS Config rules

Also shows a brief history of configuration changes tracked by AWS Config."></outline>
                            <outline text="CloudTrail Events" _note="Displays 
each resource in the group
the resource type
the last event that CloudTrail recorded against the resource."></outline>
                            <outline text="Personal Health
Dashboard" _note="Contains alerts when AWS experiences an issue that may impact your resources.

Also shows you the number of events that AWS resolved within the last 24 hours."></outline>
                            <outline text="Trusted Advisor
Recommendations" _note="Can check your AWS environment for optimisations and recommendations for cost optimisation, performance, security and fault tolerance.

Will also snow when you've exceeded 80% of your limit for a service.

Business and Enterprise support customers get full access to all Trusted Advisor checks.
All AWS customers get some (see website for more details)."></outline>
                        </outline>
                    </outline>
                    <outline text="AWS Systems
Manager Inventory" _note="Collects data from your instances including OS and app versions.

Can collect data for the following:

- OS name and version
- Apps and filenames, versions and sizes
- Network configuration, including IP and media access control (MAC) addresses
- Windows updates, roles, services and registry values
- CPU model, cores and speed

You control which instances to collect data from

You can have a region-wide inventory association

You can choose all instances in your account manually or by tag

This is called a global inventory association">
                        <outline text="Compliance" _note="Shows how the patch and association status of your instances stack up against the rules you've configured.

Patch compliance
The number of instances that have the patches in their configured baseline, as well as details of the specific patches installed.

Association compliance
The number of instances that have had an association successfully executed against them."></outline>
                    </outline>
                </outline>
                <outline text="Running Containers" _note="AWS provides two distinct services for running containers in production.

Amazon Elastic Container Service (ECS)

Amazon Elastic Kubernetes Service (EKS)">
                    <outline text="Amazon Elastic
Container Service" _note="Use  to

Define your application
Select the container images
Select the environment resources
Select any other elements your application will need.


ECS will take care of the rest

It will oversee provisioning the necessary AWS instances, storage and networking resources.

It will also provide the tools to monitor and administer your deployment throughout its life cycle.">
                        <outline text="Amazon ECS Anywhere" _note="A service built on top of ECS that extends the ECS platform to your own infrastructure.

It makes the same API and tools you might already use in ECS in the cloud available for your on-prem container workloads.

Can be helpful for hybrid deployments (e.g. some stuff left on-prem)

Regardless, there are still costs to use this service.

Enabled by using an activation key to install/launch ECS and SSM agents on each of your local servers."></outline>
                    </outline>
                    <outline text="Amazon Elastic
Kubernetes Service" _note="K8s.

Open source container orchestrator.

Popular - all major cloud providers offer K8s services.">
                        <outline text="Amazon EKS Anywhere" _note="Similar service to Amazon ECS Anywhere but for K8s instead.

However, Amazon EKS Distro 
- is a freely available package you can donwload
- makes it easy for you to closely control the versions and environment dependencies.
- handles a lot of the updates and standardisation that can sometimes become overly distracting."></outline>
                    </outline>
                    <outline text="Other
Container-Oriented
Services">
                        <outline text="AWS Fargate" _note="This is for user who don't need any control over the infrastructure supporting their container deployments.

It can abstract away a lot of the complexity.

It can be configured to use either the ECS or EKS platform invisibly to run your application in a secure, isolated environment.



--- 

Separate not from chatGPT just to clarify why a platform still needs to be chosen

Fargate's Abstraction is for Infrastructure, Not Orchestration:
 • Fargate doesn’t manage how applications are orchestrated; it just manages the compute resources. The orchestration platform (ECS or EKS) governs how tasks/pods are scheduled, monitored, and interact with one another."></outline>
                        <outline text="Amazon Elastic
Container Registry
(ECR)" _note="A managed Docker container registry service

Makes it easy for devs to store, manage and deploy Docker container images.

It eliminates the need to manage your images on platforms like GitHub (or even to build and manage your own container repositories).

Via integration with IAM, it provides resource-level control of each repository so that access can be strictly controlled.

Also fully integrated with both ECS and EKS."></outline>
                    </outline>
                </outline>
            </outline>
            <outline text="Chapter 3
AWS Storage" _note="Where to keep data.

Excellent platform for
- Maintaining backup archives, log files and disaster recovery images
- Running analytics on big data at rest
- Hosting static websites

Provides inexpensive and reliable storage

Provides a space for effectively unlimited object storage.


Object storage vs Block storage

Block-level storage 
Data on a raw physical storage device is divided into individual blocks whose use is managed by a filesystem (e.g. NTFS on Windows or Btrfs/ext4 on Linux)
That filesystem is responsible for 
- allocating space for the files and data that are saved to the underlying device
- providing access whenever the OS needs to read some data

Object storage
- provides what you can think of as a flat surface on which to store your data.
- avoids related complications of block storage
- allows anyone easy access to any amount of professionally designed and maintained storage capacity

When you write files to S3, they're stored along with up to 2KB of metadata.
This is made up of
- keys that establish system details like data permissions and the appearance of a filesystem location within nested buckets.">
                <outline text="S3 Service Architecture" _note="You organise your S3 files into buckets.

By default, you're allowed to create as many as 100 buckets for each of your AWS accounts.

You can ask AWS to raise that limit.


Although an S3 bucket and its contents exist only within a single AWS region, the name you choose for your bucket must be globally unique within the entire S3 system.


Sample syntax for a typical S3 URL

s3.amazonaws.com/bucketname/filename

Same file being addressed using the AWS CLI:

s3://bucketname/filename">
                    <outline text="Prefixes and Delimiters" _note="Although S3 stores objects within a bucket on a flat surface, without subfolder hierarchies, you can use prefixes and delimiters to give your buckets the appearance of a more structured organisation.

Example of this might be

contracts/acme.pdf 

contracts being the prefix

The slash being the delimiter."></outline>
                    <outline text="Working with
Large Objects" _note="No limit to the total amount of data you can store within a bucket.

However, a single object may be no larger than 5 TB

Individual uploads can be no larger than 5 GB">
                        <outline text="Multipart Upload" _note="Use this feature to reduce the risk of data loss or aborted uploads for any object larger than 100 MB

Breaks a large object into multiple smaller parts and transmits them individually to their S3 target.

If one transmission should fail, it can be repeated without impacting the others.

Used automatically when the upload is initiated by the AWS CLI or a high-level API

(A high-level API is for operations that can be automated.  A low-level API is for when more hands-on customisation is required)."></outline>
                        <outline text="S3 Transfer Acceleration" _note="Uploads are routed through geographically nearby AWS edge locations and, from there, routed using Amazon's internal network.

If you determine this is the solution you require, you can enable the setting in your bucket.

You can then use special endpoint domain names e.g

bucketname.s3-accelerate.amazonaws.com 

for your transfers."></outline>
                    </outline>
                    <outline text="Encryption" _note="Unless intended to be publicly available, data on S3 should always be encrypted.

Use encryption keys to protect your data at rest within S3.

Use only Amazon's encrypted API endpoints for data transfers to protect data during its journeys between S3 and other locations.

Data at rest can be protected using either server-side or client-side encryption.">
                        <outline text="Server-Side Encryption" _note="You can use one of three encryption options:

- Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3), 
where AWS uses its own enterprise-standard kets to manage every step of the encryption and decryption process.

- Server0Side Encryption with AWS KMS-Managed Keys (SSE-KMS),
where, beyond the SSE-S3 features, the use of an envelope key is added along with a full audit trail for tracking key usage.  You can optionally import you own keys through the AWS KMS service.

- Server-Side Encryption with customer-Provided Keys (SSE-C),
which lets you provide your own keys for S3 to apply to its encryption."></outline>
                        <outline text="Client-Side Encryption" _note="Also possible to encrypt data before it's transferred to S3.

Done using an AWS KMS-Managed Customer Master Key (CMK).

This produces a unique key for each object before it's uploaded.

Also use a Client-Side Master Key, which you provide through the Amazon S3 encryption client."></outline>
                    </outline>
                    <outline text="Logging" _note="Disabled by default - S3 buckets can see a lot of activity, much of which is not required to be logged.

When enabled, you need to specify both a source bucket and a target bucket.

Source bucket - the bucket whose activity you're tracking.

Target bucket - the bucket to which you'd like the logs saved.

Optionals 
- prefixes and delimiters (such as creation date or time) can also be specified.

- saving from multiple source buckets into one target bucket.

- log retention policies can be applied using life-cycle rules




As expected, typical log data inclusions are:

- The account and IP address of the requestor.
- The source bucket name
- The action that was requested (GET, PUT, POST, DELETE ...)
- The time the request was issued
- The response status (including the error code)."></outline>
                </outline>
                <outline text="S3 Durability
and Availability" _note="Durability
How critical it is that your data survives no matter what

Availability
How quickly you might need to retrieve it

Both will also be impacted by how much money you have to spend.">
                    <outline text="Durability" _note="S3 measures this as a percentage.

For most S3 classes and Amazon S3 Glacier, this is 99.999999999% (11 nines)

This effectively means an average annual expected loss of 0.000000001% of objects.  

So, if you store 10 million objects with Amazon S3, on average you can expect to incur a loss of a single object once every 10,000 years! 

Essentially, it is very unlikely you would loss data stored on S3 due to infrastructure failure.



However, other things can happen that could impact and/or permanently block this data, such as:

- misconfigurations
- account lockout
- unanticipated external attacks
- even AWS going out of business (!)">
                        <outline text="High durability" _note="High durability delivered by S3 are largely because they automatically replicate your data across at least THREE availability zones.

The only exception is S3 One Zone-IA
- stores its data in only a SINGLE zone
- slightly lower availability"></outline>
                    </outline>
                    <outline text="Availability" _note="Measured as a percentage.

The percentage that you can expect a given object to be instantly available on request through the full year.

Example
Amazon S3 Standard class guarantee is 99.99% of the year.
This means &lt; 9 hours per year of downtime.

If downtime ever exceeds that limit, you can apply for a service credit.


In contrast to the 11 nines durability guarantee, this means that although there's practically no chance your data will be lost, you may not always have immediate access to it.">
                        <outline text="S3 Intelligent-Tiering" _note="Designed to save you money whilst optimising availability.

For a monthly automation fee, it will monitor the way you access data within the class over time and move an object to the lower-cost infrequent access tier if it hasn't been accessed for 30 consecutive days."></outline>
                    </outline>
                    <outline text="Eventually
Consistent Data" _note="CHANGING OR DELETING DATA
It's possible that there may be slight delays in S3 replicating any changed/deleted data across multiple locations.

To ensure no short-term conflicting data between versions, you should apply an 'eventually consistent' standard.

You should expect a delay of up to 1-2 seconds and design your operations accordingly.

ADDING NEW DATA
Because the above situation cannot occur for NEW objects, S3 instead provides read-after-write consistency for creation (PUT) operations."></outline>
                </outline>
                <outline text="S3 Object Life Cycle">
                    <outline text="Versioning" _note="By default, objects on S3 being saved will overwrite a pre-existing file with the newer version - similar to many other services.

But, if you enable versioning at the bucket level, then older copies of an object will be saved and remain accessible indefinitely.


This solves the problem of accidentally losing old data.
But it replaces it with the potential for archive bloat (many versions of the same data)."></outline>
                    <outline text="Life Cycle Management" _note="A service allowing you to automatically transition an object's storage class after a set number of days.

Example
- Have new objects remain in the S3 Standard class for the first 30 days.
- They're then moved to the cheaper One Zone-IA for another 30 days.
- If required, they could then be moved to the low-cost, long-term storage service Glacier for 365 more days before being permanently deleted.


You can optionally use prefixes to apply  life cycle rules to only certain objects within a bucket

There are minimum times (30 days, for instance) an object must remain within one class before it can be moved."></outline>
                </outline>
                <outline text="Accessing S3 Objects" _note="How to access your object data in S3 and also how to prevent access to only those requests that match your business and security needs.">
                    <outline text="Access Control" _note="By default, new S3 buckets are 
- fully accessible to your account
- not accessible to other AWS accounts
- not accessible to external visitors.


Strategic access can be opened at the bucket and object levels using any of the following:

- Access Control List (ACL) rules
- Finer-grained S3 bucket policies
- Identity and Access Management (IAM) policies

Access Points
A hostname that can point to a carefully defined subset of objects in a bucket.

Depending on how you configure your access points, clients invoking the hostname will be able to:
- read or write only the data you allow and 
- only as long as you allow it.">
                        <outline text="Access Control List (ACL)" _note="These are leftovers from before AWS created IAM

As a rule, AWS recommends applying S3 bucket policies or IAM policies rather than these."></outline>
                        <outline text="S3 Bucket Policies" _note="These 
- are in JSON format and are attached to your S3 bucket.
- make sense for cases where you want to control access to a single S3 bucket for multiple external accounts and users.

You can also limit access within bucket policies by specifying time of day or source CIDR IP address blocks


CIDR - Classless Inter-Domain Routing"></outline>
                        <outline text="Identity and Access
Management (IAM) Policies" _note="These make sense when you're trying to control the way individual users and roles access multiple resources, including S3."></outline>
                    </outline>
                    <outline text="Presigned URLs" _note="To provide temporary access to an object that's otherwise private.

The URL will be usable for a specified period of time, after which it will again become invalid.

You would specify the number of seconds with a default expiration value of 3,600 seconds (one hour)."></outline>
                    <outline text="Static Web Hosting" _note="S3 buckets can be used to host the HTML files for entire static websites.

A Static website is one where the system services used to render web pages and scripts are all client rather than server based.

S3 is excellent for this purpose as it is both inexpensive and reliable.

You can specify a root document (such as index.html) to point traffic to when accessing the URL for the bucket.

You can use Amazon Route 53 to direct requests to a specific DNS domain name.  However, this will only work if your domain name is also the name of the S3 bucket.

You can also get a free SSL/TLS certificate to encrypt your site by requesting a certificate from AWS Certificate Manager (ACM) and importing it into a CloudFront distribution that specifies your S3 bucket as its origin.


S3 Select or S3 Glacier Select
AWS provides a different way to access data stored on either of these.
You can apply SQL-like queries to stored objects.
This means only relevant data from within objects is retrieved.
This permits significantly more efficient and cost-effective operations."></outline>
                </outline>
                <outline text="Amazon S3 Glacier" _note="May initially seem to be similar to other S3 storage classes.

Important differences
Its archives are encrypted by default (on S3 it's an option you have to select).
Unlike S3's 'human-readable' key names, Glacier's are given machine-generated IDs.

Biggest difference 
The time it takes to retrieve your data.
It can take a number of hours (vs almost instant access from S3).

Purpose
To provide inexpensive long-term access to storage for data that will be needed only in unusual and infrequent circumstances.

NB - It does provide Expedited retrievals, getting your data in minutes rather than hours.  This would incur a premium charge.


Terminology
&quot;Archive&quot; - used to describe an object (doc, video, TAR, ZIP etc)
&quot;Vaults&quot; - The Glacier equivalent of S3's buckets.
(Glacier vault names do not have to be globally unique).

Other chargeable services are
- data retrievals
- PUT, COPY, POST or LIST requests
- life cycle transition requests.">
                    <outline text="Amazon S3 Glacier
Instant Retrieval (quickest, more expensive)"></outline>
                    <outline text="Amazon S3 Glacier
Flexible Retrieval"></outline>
                    <outline text="Amazon S3 Glacier
Deep Archive (slowest, least expensive)"></outline>
                </outline>
                <outline text="Other
Storage-Related
Services">
                    <outline text="Amazon Elastic
File System" _note="Provides automatically scalable and shareable file storage to be accessed from Linux instances.

Files designed to be accessed from within a VPC via NFS mounts on EC2 Linux instances or from your on-premises servers through AWS Direct Connect.

Goal is to make it easy to enable secure, low-latency and durable file sharing among multiple instances."></outline>
                    <outline text="Amazon FSx" _note="Fully managed service that provides scalable, high-performance file storage in the cloud.

It is designed to support applications and workloads that require shared file storage with low-latency access. FSx offers file systems optimised for specific use cases and performance needs.

It comes in four flavours (file system options).">
                        <outline text="FSx for Lustre"></outline>
                        <outline text="FSx for Windows
File Server"></outline>
                        <outline text="FSx for OpenZFS"></outline>
                        <outline text="FSx for NetApp ONTAP"></outline>
                    </outline>
                    <outline text="AWS Storage Gateway" _note="Functions as a cloud virualisation of a local physical backup device (like a tape drive). 

The data itself is saved to AWS platforms like S3 and EBS.

Data can be maintained in a local cache to make it locally available."></outline>
                    <outline text="AWS Snow Family" _note="Rather than using a normal internet connection to migrate large data sets can require far too much time and bandwidth to be practical.

A Snow device is a good solution when looking to move terabyte/petabyte-scaled data.

AWS can send a physical appropriately-sized device.
Once data transferred, you can send it back and Amazon will then transfer your data to buckets on S3.

In addition, some of the more rugged devices can also be used in connected edge locations.

All devices are 256-bit encrypted and HIPAA-compliant.">
                        <outline text="Snowcone"></outline>
                        <outline text="Snowball" _note="Two versions available, based on your requirements:

- Snowball Edge Storage Optimised
- Snowball Edge Compute Optimised"></outline>
                        <outline text="Snowmobile" _note="Waterproof
Tamper-resistant
45 foot long shipping container
Meant for petabyte/exabyte data migrations."></outline>
                    </outline>
                    <outline text="AWS DataSync" _note="Specialises in on-prem data stores into your AWS account with a minimum of fuss.

Works over regular internet connection.

More flexible than Snowball 
- not limited to S3
- not limited to RDS like you are with AWS Database Migration Service.

You can drop your data into any service within your AWS account.

- quickly and securely move old data out of your expensive datacenter into cheaper S3 or Glacier storage.
- Transfer data sets directly into S3, EFS, or FSx, where it can be processed and analysed by your EC2 instances.
- Apply the power of any AWS service to any class of data as part of an easy-to-configure automated system.

Can handle external transfer rates of up to 10Gbps
Offers both encryption and data validation."></outline>
                </outline>
            </outline>
            <outline text="Chapter 4 Amazon Virtual
Private Cloud (VPC)" _note="A VPC is a virtual network that can contain EC2 instances as well as network resources for other AWS services.

By default, every VPC is logically isolated from all other networks but can connect your VPC to other networks such as:
- the internet, 
- on-prem networks and 
- other VPCs

It can exist only within an AWS region.
However, you can 
- have multiple VPCs in your account
- create multiple VPCs in a single region

They are scalable.">
                <outline text="VPC CIDR Blocks" _note="Classless Inter-Domain Routing

Determines which IP addresses may be assigned to instances and other resources within the VPC.">
                    <outline text="Primary CIDR Blocks" _note="You must assign a primary CIDR block when creating a VPC.

CIDR notation (slash notation)
For example, 
172.16.0.0/16 includes all addresses from 
172.16.0.0 to 172.16.255.255
(That's 65,536 addresses)

CIDR block is also known as an IP prefix.
The /16 portion is the prefix length.
The prefix length refers to the length of the subnet mask.
In the case of a VPC CIDR this can range between /16 to /28.

So, there's an inverse relationship between prefix length and number of IP addresses in the CIDR

- a /28 prefix length gives only 16 possible addresses
- a /16 prefix length gives 65,536 possible addresses

Valid IPv4 prefix lengths range from /0 to /32.

To avoid conflicts with public Internet addresses, it's best to use:

- 10.0.0.0 - 10.255.255.255   (10.0.0.0/8)
- 172.16.0.0 - 172.31.255.255   (172.16.0.0/12)
- 192.168.0.0 - 192.168.255.255  (192.168.0.0/16)

You can't change the primary CIDR block after you create your VPC!"></outline>
                    <outline text="Secondary CIDR Blocks" _note="Optional

Must come from 
- the same address range as the primary OR 
- a publicly routable range.

But they must not overlap with either
- the primary block
- other secondary blocks"></outline>
                    <outline text="IPv6 CIDR Blocks" _note="Unlike the primary CIDR that you can choose, you can't choose your own arbitrary IPv6 CIDR - instead, AWS assigns one to your VPC at your request.

It will be publicly routable - so all IPv6 addresses are reachable from the internet.

The prefix length of an IPv6 VPC CIDR assigned by AWS.  

The prefix length of an IPv6 VPC CIDR assigned by AWS is always /56.

If you already own a public IPv6 CIDR block, it's possible to assign it to your VPC using the bring your own IP address (BYOIP) feature."></outline>
                    <outline text="Subnets" _note="A logical container within a VPC that holds VPC resources, including your EC2 instances.

Lets you 
- isolate instances from one another
- control how traffic flows to and from your instances
- organises them by function.

(Similar to virtual LANs in a traditional network)


Every (EC2) instance must exist within a subnet.
After you create an instance in a subnet, you can't move the instance.
You also can't move an instance from one VPC or availability zone to another.

However, you can terminate it and recreate a different instance in another subnet (and preserve the data by:
- snapshotting the volume, 
- creating an AMI and then 
- using that AMI to create a new instance in another subnet.">
                        <outline text="Subnet CIDR Blocks" _note="From the VPC CIDR block, you carve out a smaller CIDR block for each subnet.

Example:
- if VPC has CIDR of 172.16.0.0/16
- one of your subnets may have a CIDR of 172.16.100.0/24
- this range includes all IP addresses from 172.16.100.0 to 172.16.100.255 (256 addresses)

AWS reserves the first four and last IP addresses in every subnet

So, assuming a subnet CIDR of 172.16.100.0/24, the following addresses would be reserved:

- 172.16.100.0
- 172.16.100.1 (implied router)
- 172.16.100.2 (Amazon-provided DNS server)
- 172.16.100.3 (reserved)
- 172.16.100.255

It's possible for a subnet and VPC to share the same CIDR.
Not common and won't leave you room for additional subnets.
Meaning your VPC would be effectively limited to one availability zone.

More common to have each subnet's prefix length longer than the VPC's CIDR block
This would allow multiple subnets to exist in the same VPC.
(e.g. subnet - 192.168.0.0/16 within VPC 192.168.3.0/24 )

A subnet can't have multiple CIDRs (unlike a VPC that can have secondary CIDR).
However, a subnet can be derived from either the primary or secondary CIDR of a VPC.
(e.g. VPC 
primary 172.16.0.0/16 and 
secondary 172.17.0.0/16 
means a subnet of 172.17.12.0/24 could be used as it falls inside the secondary CIDR
)"></outline>
                        <outline text="Availability Zones" _note="A subnet can exist within only one availability zone (i.e a datacenter)

Resiliency for applications can be achieved by 
- creating two subnets each in a different availability zone and then 
- spreading your instances across those zones, e.g :

Subnet   Availability zone  Instance
web-subnet1  us-east-1a   web1
web-subnet2  us-east-1b   web2"></outline>
                        <outline text="IPv6 CIDR Blocks" _note="If you've allocated an IPv6 CIDR to your VPC, you can assign IPv6 CIDRs to subnets within that VPC.

The prefix length for an IPv6 subnet is fixed at /64.

NB - You must always assign an IPv4 CIDR block to a subnet, even if you intend to use only IPv6."></outline>
                    </outline>
                </outline>
                <outline text="Elastic Network Interfaces" _note="ENI - elastic network interface
Its a virtual network interface that allows an instance to communicate with other network resources including:
- AWS services,
- other instances
- on-premises servers
- the Internet.

It also makes it possible for you to use SSH or RDP to connect to the OS running on your instance to manage it.

First ENI attached to an instance is called the primary network interface (aka primary ENI)
This is connected to only one subnet.

You can't removed the primary ENI from an instance and you can't change its subnet.">
                    <outline text="Primary and Secondary
Private IP Addresses" _note="Each instance must have a primary private IP address from the range specified by the subnet.

The primary private IP address is bound to the primary ENI of the instance.

You cannot change/remove this address.

But you can assign secondary private IP addresses to the primary ENI.

As above, the secondary private IP address must also come from the same subnet that the ENI is attached to.


It is possible to attach additional ENIs to an instance.  Those ENIs may be in a different subnet, but they must be in the same availability zone as the instance.

As always, any addresses assigned to the ENI must come from the CIDR of the subnet to which it is attached."></outline>
                    <outline text="Attaching Elastic
Network Interfaces" _note="An ENI can exist independently of an instance.  You can create an ENI first and then attach it to an instance later.

e.g. 
create an ENI in one subnet and then 
attach it to an instance in the same subnet as the primary ENI when you launch the instance.

If you disable the Delete On Termination attribute of the ENI, you can terminate the instance without deleting the ENI.  You can then associate the ENI with another instance.

You can also 
take an existing ENI that's not attached to an instance and
attach it to an existing instance as a secondary ENI.

This lets you 
redirect traffic from a failed instance to a working instance 
by 
detaching the ENI from the failed instance and 
reattaching it to the working instance."></outline>
                    <outline text="Enhanced Networking" _note="Another option for virtual network interfaces.

In contrast to ENIs, these offer:
- Higher network throughput speeds
- Lower latency

They use
Single-root input/output virtualisation (SR-IOV) to allow an instance direct access to the physical network interface of the host.

This means 
bypassing the hypervisor and resulting in 

- lower CPU utilisation and 
- better network performance.


Two ways:

- Elastic Network Adaptor (ENA)
 supports throughput speeds up to 100Gbps.
 most instance types support it.
- Intel 82599 Virtual Function Interface (VF)
 supports speeds up to 10Gbps
 only a few instance types that don't support ENAs can use this.

The OS of the instance you are using must include the appropriate drivers to support enhanced networking."></outline>
                </outline>
                <outline text="Internet Gateways" _note="Gives instances the ability to 
- obtain a public IP address
- connect to the internet
- receive requests from the internet

Default VPC 
has an internet gateway associated with it by default.

Custom VPC
Does not have an internet gateway associated with it.
You must create an internet gateway and associate it with a VPC.

You can only associate one internet gateway with a VPC, but you can create multiple internet gateways and associate each one with a different VPC.

So, each VPC only has one internet gateway.


Essentially the front door to a VPC
It has a resource ID which will begin with igw- followed by an alphanumeric string.

To use an internet gateway, you must
- create a default route in a route table that points to the internet gateway as a target."></outline>
                <outline text="Route Tables" _note="To control how traffic enters/leaves and moves around within your VPC, you need to use routes stored in route tables.

VPC architecture implements IP routing as a software function that AWS calls an implied router (or implicit router).

You only have to manage the route table that the implied router uses.

Each route table consists of 
- one or more routes and
- at least one subnet association.


When you create a VPC, AWS automatically creates a default route table association.

If you do not explicitly associate a subnet with a custom route table you've created, AWS will implicitly associate it with the main route table.">
                    <outline text="Routes" _note="Routes determine how to forward traffic to or from resources within the subnets associated with the route table.

IP routing is destination-based
- routing decisions are based only on the destination IP prefix, not the source IP address.

When creating a route, you must provide the following elements:
- Destination IP prefix
 Must be IPv4 or IPv6 prefix in CIDR notation.
- Target resource
 Must be an AWS network resource (internet gateway or an ENI). Cannot be an IP prefix.


Every route table contains a local route that allows instances in different subnets to communicate with each other.

Example.  

If the VPC has a CIDR 172.31.0.0/16

---------------------
Destination.   | Target
---------------------
172.31.0.0/16 | Local
---------------------

This local route is the only default route that exists in every route table.
It is what allows communication between instances in the same VPC.

Because there are no other specified routes, all traffic destined for an address outside of the VPC CIDR range will get dropped."></outline>
                    <outline text="The Default Route" _note="To enable internet access for your instances, you must create a default route pointing to the internet gateway.

It would look something like this

-------------------------------------------------
Destination.    | Target          |
-------------------------------------------------
172.31.0.0/16 | Local          |
-------------------------------------------------
0.0.0.0/0       | igw-0e538022a0fddc318     |
-------------------------------------------------


The 0.0.0.0/0 prefix encompasses all IP addresses including those of the internet.

PUBLIC SUBNET.: Any subnet that's associated with a route table containing a route pointing to an internet gateway.
PRIVATE SUBNET: Does not have a route with an internet gateway as a target


NOTE 
The default and local routes in the above table overlap, since the default route every possible prefix of the local one.
The actual order of the routes doesn't matter -the implied router will route based on the closest match.

However, if 198.51.100.50 was used (for example), then this would be routed via the default route.  It isn't part of the local route but will always end up being part of the default one."></outline>
                </outline>
                <outline text="Security Groups" _note="Functions as a firewall that controls traffic to and from an instance.
It does this by permitting traffic to ingress or egress that instance's ENI (Elastic Network Interface)

- Every ENI must have at least one security group associated with it.
- One ENI can have multiple security groups attached.
- The same security group can be attached to multiple ENIs


NOTE
Most instances have only one ENI - so people think of a security group being attached to an instance.
But an instance can have many ENIs - so take care to note whether those ENIs use different security groups.



When you create a security group, you must specify
- a group name
- description
- a VPC for the group to reside in

Once created the group, you then create
- inbound rules
- outbound rules
These specify what traffic the security group allows.

If you don't explicitly allow traffic using a rule, the security group will block it.">
                    <outline text="Inbound Rules" _note="Specifies what traffic is allowed to ingress the attached ENI.

Rules consist of three required elements:

- Source
- Protocol
- Destination port range.


When first created, 
- a security group does not contain any inbound rules.
- they use a default-deny approach (aka whitelisting), which denies all traffic that is not explicitly allowed by a rule.
- so, all inbound traffic will be blocked.


As an example... 
If you wanted to have an instance running an HTTPS-based web application, you would need
- an inbound rule to allow all TCP traffic coming in on port 443
If you then also wanted to use SSH, you would need
- another inbound rule to allow TCP port 22

But you may only want SSH inbound traffic from one specific IP address.  The below example would allow ALL inbound to port 443 and only inbound from 198.5.100.10 on port 22.

-------------------------------------------------
Source   Protocol  Port range
-------------------------------------------------
198.51.100.10/32 TCP   22
-------------------------------------------------
0.0.0.0/0   TCP   443
-------------------------------------------------


NOTE - The order of rules in a security group doesn't matter."></outline>
                    <outline text="Outbound Rules" _note="Specify what traffic the instance may send out of the attached ENI.

Similar to Inbound Rules, these also contain three elements:

- Destination
- Protocol
- Destination port range

Outbound rules are less restrictive, since there's no real security risk in sending requests outbound to the internet (especially since any response will then be subject to the relevant Inbound Rule).

By default, the following outbound rule is automatically created:

-------------------------------------------------
Destination    Protocol  Port range
-------------------------------------------------
0.0.0.0/0   All  All
-------------------------------------------------

Clearly, if you delete that rule, then the instance will be fully unable to communicate with the internet."></outline>
                    <outline text="Sources and Destinations" _note="Both the Source and Destination in a rule can be any CIDR

The source can also be the resource ID of a security group.

If you do this, then the rule will permit the traffic to any instance with that security group attached.
This makes it easy to allow instances to communicate with each other by simply assigning the same security group to all of them.

The source security group you use can exist in a different AWS account.
You'll need to specify the AWS account owner ID in order to specify a source security group in a different account."></outline>
                    <outline text="Stateful Firewall" _note="A security group acts as a stateful firewall.

Stateful 
- when a security group allows traffic to pass in one direction
- it intelligently allows reply traffic in the opposite direction

Example being 
- when you allow an instance outbound access to download updates from a software repository on the internet
- the security group automatically allows reply traffic back into the instance.

This is done using connection tracking to determine whether to allow response traffic to pass.

Flow information checked includes:

- Protocol
- Source and destination IP address
- Source and destination port number

This helps identify reply traffic that belongs to the same flow and distinguish it from unsolicited traffic."></outline>
                </outline>
            </outline>
            <outline text="Chapter 5
Database
Services"></outline>
            <outline text="Chapter 6 Authentication and
Authorisation - AWS Identity and
Access Management"></outline>
            <outline text="Chapter 7 CloudTrail,
CloudWatch and AWS Config"></outline>
            <outline text="Chapter 8 The Domain Name
System and Network"></outline>
            <outline text="Chapter 9 Data Ingestion,
Transformation and Analytics"></outline>
            <outline text="Chapter 10 Resilient
Architectures"></outline>
            <outline text="Chapter 11
High-Performing
Architectures"></outline>
            <outline text="Chapter 12 Secure
Architectures"></outline>
            <outline text="Chapter 13
Cost-Optimised
Architectures"></outline>
        </outline>
    </body>
</opml>